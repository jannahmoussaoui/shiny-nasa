library(shiny); runApp('App_demo.R')
getwd()
library(tidyr)
library(dplyr)
library(shiny)
library(shinysurveys)
library(tibble)
library(googlesheets4)
gs4_auth(email = "jannahmoussaoui@gmail.com", cache = ".secrets")
runApp('App_demo.R')
runApp('App_survey.R')
runApp('App_survey.R')
drive_auth(email = "jannahmoussaoui@gmail.com", cache = ".secrets")
library(googledrive)
library(googledrive)
drive_auth(email = "jannahmoussaoui@gmail.com", cache = ".secrets")
runApp('App_survey.R')
load("C:/_MYWORK/xFTM/ftm_shinynasa/.RData")
library(shiny); runApp('C:/_MYWORK/xFTM/shiny/nasa/App_survey.R')
runApp('C:/_MYWORK/xFTM/shiny/nasa/App_survey.R')
runApp('C:/_MYWORK/xFTM/shiny/nasa/App_survey.R')
forgetDeployment()
?forgetDeployment()
library(rsconnect)
forgetDeployment()
Y
applications()
forgetDeployment()
library(shiny); runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
library(tidyverse)
library(magrittr)
library(ggplot2)
library(dplyr)
library(cowplot)
#read data in
raw_data<-read.csv("nasa.csv")
raw_data2<-read.csv("nasa_group.csv")
#read data in
raw_data<-read.csv("nasa.csv")
raw_data2<-read.csv("nasa_group.csv")
#remove unwanted columns
remove_metadata<-raw_data[, -c(0:17)]
remove_metadata2<-raw_data2[, -c(0:17)]
#remove unwanted rows
dat<-remove_metadata[-c(1,2),]
dat2<-remove_metadata2[-c(1,2),]
#convert columns to numeric
dat[, 2:16] <- lapply(dat[, 2:16], as.numeric)
dat2[, 2:16] <- lapply(dat2[, 2:16], as.numeric)
dat$Source <- "Individual"
dat2$Source <- "Group"
dat %<>% rbind(dat2) %>% relocate(Source)
true_scores <- c(15, 4, 6, 8, 13, 11, 12, 1, 3, 9, 14, 2, 10, 7, 5)
# pivot the table into long format
## while we do this, extract the item numbers from
## column names and convert them to numbers
## also extract the group label (a single letter)
## from each ID code
dat %<>% pivot_longer(cols = 3:17) %>%
mutate(item = name %>% str_split_i("_", 2) %>% as.numeric(),
Group = str_sub(ID, 1, 1))
dat %<>% relocate(Source, Group, ID, item, value) %>% select(-name)
# create a column of error scores
dat %<>% mutate(true_score = !!true_scores[dat$item], abs_error = abs(value - true_score))
# aggregate scores using the Borda method
## just just requires us to average the item rankings from individuals,
## then convert those to ranks
Borda <- dat %>% group_by(Group, item) %>% summarize(M = mean(value)) %>% ungroup()
Borda %<>% reframe (Group, item, value = rank(M), by = Group)
# calculate error scors for Borda rankings, then get group averages
Borda %<>% mutate(true_score = !!true_scores[Borda$item], error = abs(value - true_score))
Borda %<>% group_by(Group) %>% summarize(abs_error = mean(error))%>% mutate(Source = "Aggregate")
#define the bin intervals and labels
bins <- c(-1, 25, 32, 45, 55, 70, 113)
labels <- c("Excellent (0-25)", "Good (26-32)", "Average (33-45)", "Fair (46-55)", "Poor (56-70)", "Very Poor (71-112)")
# Create a new data frame combining individual and group data
combined_data <- dat %>%group_by(Source, ID)%>% summarize(abs_error = sum(abs_error)) %>% ungroup()
# Draw a combined histogram with labels
ggplot(combined_data, aes(x = cut(abs_error, breaks = bins, labels = labels), fill = Source)) +
geom_bar(position = position_dodge(width = 0.8), color = "#FFFFFF") +
geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.5, size = 3) +
scale_fill_manual(values = c(Individual = "#ED2024", Group = "#FFCDD2")) +
scale_x_discrete(labels = labels, drop = FALSE) +
scale_y_continuous(breaks = function(x) unique(floor(pretty(seq(0, (max(x) + 1) * 1.1))))) +
labs(title = "Frequency Distribution of Error Scores",
x = "NASA Rating (Range of Error Scores)",
y = "Count") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))
# combined data will hold individual, group, and aggregate scores
## get summed error score by source, group, and ID
combined_data <- dat %>%
group_by(Source, ID, Group) %>%
summarize(abs_error = sum(abs_error)) %>% ungroup()
# put the Borda scores in the same format as the combined_data object
Borda %<>% mutate(ID = str_c("agg_", "Group")) %>% relocate(Source, ID, Group, abs_error)
combined_data %<>% rbind(Borda)
combined_data %<>% mutate(Source = as.factor(Source) %>% fct_relevel( "Individual", "Group", "Aggregate"))
combined_data %<>% mutate(ID_label = if_else(Source == "Individual", ID, ""))
ggplot(combined_data, aes(x = Group, y = abs_error, fill = Source, group = ID)) +
geom_bar(stat = "identity", position = position_dodge(.8), width = 0.75, alpha = .5, color = "lightgray") +
geom_point(stat = "identity", aes(fill = Source), position = position_dodge(.8), shape = 21,  size = 3, show.legend = FALSE) +
geom_text(aes(label = ID_label),
position = position_dodge(0.8), vjust = .5, size = 4, angle = 90, hjust = -.15) +
scale_fill_manual(values = c(Individual = "#ED2024", Group = "#FFCDD2", Aggregate = "blue")) +
labs(title = "Errors for groups, aggregation, and individuals", x = "Groups", y = "Absolute Error") +
theme_minimal() +
theme(legend.position = "top", legend.key.size = unit(20, "point"), legend.spacing.x = unit(10, "point"),
legend.title = element_blank(),
legend.text = element_text(size = 12),
plot.title = element_text(hjust = 0.5, size = 15)) +
coord_cartesian(ylim = c(0, 125))
library(tidyverse)
library(magrittr)
library(ggplot2)
library(dplyr)
library(cowplot)
#read data in
raw_data<-read.csv("nasa.csv")
raw_data2<-read.csv("nasa_group.csv")
#remove unwanted columns
remove_metadata<-raw_data[, -c(0:17)]
remove_metadata2<-raw_data2[, -c(0:17)]
#remove unwanted rows
dat<-remove_metadata[-c(1,2),]
dat2<-remove_metadata2[-c(1,2),]
#convert columns to numeric
dat[, 2:16] <- lapply(dat[, 2:16], as.numeric)
dat2[, 2:16] <- lapply(dat2[, 2:16], as.numeric)
dat$Source <- "Individual"
dat2$Source <- "Group"
dat %<>% rbind(dat2) %>% relocate(Source)
true_scores <- c(15, 4, 6, 8, 13, 11, 12, 1, 3, 9, 14, 2, 10, 7, 5)
# pivot the table into long format
## while we do this, extract the item numbers from
## column names and convert them to numbers
## also extract the group label (a single letter)
## from each ID code
dat %<>% pivot_longer(cols = 3:17) %>%
mutate(item = name %>% str_split_i("_", 2) %>% as.numeric(),
Group = str_sub(ID, 1, 1))
dat %<>% relocate(Source, Group, ID, item, value) %>% select(-name)
# create a column of error scores
dat %<>% mutate(true_score = !!true_scores[dat$item], abs_error = abs(value - true_score))
# aggregate scores using the Borda method
## just just requires us to average the item rankings from individuals,
## then convert those to ranks
Borda <- dat %>% group_by(Group, item) %>% summarize(M = mean(value)) %>% ungroup()
Borda %<>% reframe (Group, item, value = rank(M), by = Group)
# calculate error scors for Borda rankings, then get group averages
Borda <- Borda %>%
group_by(Group) %>%
mutate(
true_score = if_else(n_distinct(ID) == 1, value, !!true_scores[item]),
error = abs(value - true_score)
) %>%
summarize(abs_error = mean(error), Source = "Aggregate")
View(Borda)
true_scores <- c(15, 4, 6, 8, 13, 11, 12, 1, 3, 9, 14, 2, 10, 7, 5)
# pivot the table into long format
## while we do this, extract the item numbers from
## column names and convert them to numbers
## also extract the group label (a single letter)
## from each ID code
dat %<>% pivot_longer(cols = 3:17) %>%
mutate(item = name %>% str_split_i("_", 2) %>% as.numeric(),
Group = str_sub(ID, 1, 1))
#read data in
raw_data<-read.csv("nasa.csv")
raw_data2<-read.csv("nasa_group.csv")
#remove unwanted columns
remove_metadata<-raw_data[, -c(0:17)]
remove_metadata2<-raw_data2[, -c(0:17)]
#remove unwanted rows
dat<-remove_metadata[-c(1,2),]
dat2<-remove_metadata2[-c(1,2),]
#convert columns to numeric
dat[, 2:16] <- lapply(dat[, 2:16], as.numeric)
dat2[, 2:16] <- lapply(dat2[, 2:16], as.numeric)
dat$Source <- "Individual"
dat2$Source <- "Group"
dat %<>% rbind(dat2) %>% relocate(Source)
true_scores <- c(15, 4, 6, 8, 13, 11, 12, 1, 3, 9, 14, 2, 10, 7, 5)
# pivot the table into long format
## while we do this, extract the item numbers from
## column names and convert them to numbers
## also extract the group label (a single letter)
## from each ID code
dat %<>% pivot_longer(cols = 3:17) %>%
mutate(item = name %>% str_split_i("_", 2) %>% as.numeric(),
Group = str_sub(ID, 1, 1))
dat %<>% relocate(Source, Group, ID, item, value) %>% select(-name)
# create a column of error scores
dat %<>% mutate(true_score = !!true_scores[dat$item], abs_error = abs(value - true_score))
# aggregate scores using the Borda method
## just just requires us to average the item rankings from individuals,
## then convert those to ranks
Borda <- dat %>% group_by(Group, item) %>% summarize(M = mean(value)) %>% ungroup()
Borda %<>% reframe (Group, item, value = rank(M), by = Group)
# calculate error scors for Borda rankings, then get group averages
Borda %<>% mutate(true_score = !!true_scores[Borda$item], error = abs(value - true_score))
Borda <- Borda %>%
group_by(Group) %>%
mutate(
true_score = if_else(n_distinct(ID) == 1, value, !!true_scores[item]),
error = abs(value - true_score)
) %>%
summarize(abs_error = mean(error), Source = "Aggregate")
View(Borda)
View(Borda)
#read data in
raw_data<-read.csv("nasa.csv")
raw_data2<-read.csv("nasa_group.csv")
#remove unwanted columns
remove_metadata<-raw_data[, -c(0:17)]
remove_metadata2<-raw_data2[, -c(0:17)]
#remove unwanted rows
dat<-remove_metadata[-c(1,2),]
dat2<-remove_metadata2[-c(1,2),]
#convert columns to numeric
dat[, 2:16] <- lapply(dat[, 2:16], as.numeric)
dat2[, 2:16] <- lapply(dat2[, 2:16], as.numeric)
dat$Source <- "Individual"
dat2$Source <- "Group"
dat %<>% rbind(dat2) %>% relocate(Source)
true_scores <- c(15, 4, 6, 8, 13, 11, 12, 1, 3, 9, 14, 2, 10, 7, 5)
# pivot the table into long format
## while we do this, extract the item numbers from
## column names and convert them to numbers
## also extract the group label (a single letter)
## from each ID code
dat %<>% pivot_longer(cols = 3:17) %>%
mutate(item = name %>% str_split_i("_", 2) %>% as.numeric(),
Group = str_sub(ID, 1, 1))
dat %<>% relocate(Source, Group, ID, item, value) %>% select(-name)
# create a column of error scores
dat %<>% mutate(true_score = !!true_scores[dat$item], abs_error = abs(value - true_score))
# aggregate scores using the Borda method
## just just requires us to average the item rankings from individuals,
## then convert those to ranks
Borda <- dat %>% group_by(Group, item) %>% summarize(M = mean(value)) %>% ungroup()
Borda %<>% reframe (Group, item, value = rank(M), by = Group)
# calculate error scors for Borda rankings, then get group averages
Borda %<>% mutate(true_score = !!true_scores[Borda$item], error = abs(value - true_score))
Borda <- Borda %>%
group_by(Group) %>%
mutate(
true_score = if_else(n_distinct(ID) == 1, value, true_scores[match(item, Borda$item)]),
error = abs(value - true_score)
) %>%
summarize(abs_error = mean(error), Source = "Aggregate")
#read data in
raw_data<-read.csv("nasa.csv")
raw_data2<-read.csv("nasa_group.csv")
#remove unwanted columns
remove_metadata<-raw_data[, -c(0:17)]
remove_metadata2<-raw_data2[, -c(0:17)]
#remove unwanted rows
dat<-remove_metadata[-c(1,2),]
dat2<-remove_metadata2[-c(1,2),]
#convert columns to numeric
dat[, 2:16] <- lapply(dat[, 2:16], as.numeric)
dat2[, 2:16] <- lapply(dat2[, 2:16], as.numeric)
dat$Source <- "Individual"
dat2$Source <- "Group"
dat %<>% rbind(dat2) %>% relocate(Source)
true_scores <- c(15, 4, 6, 8, 13, 11, 12, 1, 3, 9, 14, 2, 10, 7, 5)
# pivot the table into long format
## while we do this, extract the item numbers from
## column names and convert them to numbers
## also extract the group label (a single letter)
## from each ID code
dat %<>% pivot_longer(cols = 3:17) %>%
mutate(item = name %>% str_split_i("_", 2) %>% as.numeric(),
Group = str_sub(ID, 1, 1))
dat %<>% relocate(Source, Group, ID, item, value) %>% select(-name)
# create a column of error scores
dat %<>% mutate(true_score = !!true_scores[dat$item], abs_error = abs(value - true_score))
# aggregate scores using the Borda method
## just just requires us to average the item rankings from individuals,
## then convert those to ranks
Borda <- dat %>% group_by(Group, item) %>% summarize(M = mean(value)) %>% ungroup()
Borda %<>% reframe (Group, item, value = rank(M), by = Group)
# calculate error scors for Borda rankings, then get group averages
#Borda %<>% mutate(true_score = !!true_scores[Borda$item], error = abs(value - true_score))
Borda <- Borda %>%
group_by(Group) %>%
mutate(
true_score = if_else(n_distinct(ID) == 1, value, true_scores[match(item, Borda$item)]),
error = abs(value - true_score)
) %>%
summarize(abs_error = mean(error), Source = "Aggregate")
View(Borda)
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
install.packages("shinyjs")
install.packages("shinyjs")
# Let's disable the plot results button until a session name is provided (avoids the no user id issue)
shinyjs::disable("plotResultsBtn")
library(shiny); runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
runApp('App_demo.R')
